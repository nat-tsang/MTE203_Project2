@article{gursen,
title = {Definition of artificial neural networks with comparison to other networks},
journal = {Procedia Computer Science},
volume = {3},
pages = {426-433},
year = {2011},
note = {World Conference on Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.12.071},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910004461},
author = {Erkam Guresen and Gulgun Kayakutlu},
keywords = {Artificial neural network (ANN), Graph theory},
abstract = {Definition of Artificial Neural Networks (ANNs) is made by computer scientists, artificial intelligence experts and mathematicians in various dimensions. Many of the definitions explain ANN by referring to graphics instead of giving well explained mathematical definitions; therefore, misleading weighted graphs (as in minimum cost flow problem networks) fit the definition of ANN. This study aims to give a clear definition that will differentiate ANN and graphical networks by referring to biological neural networks. The proposed definition of ANN is a mathematical definition, from the point of graph theory which defines ANN as a directed graph. Then differences between ANNs and other networks will be explained by examples using proposed definition.}
}
@misc{grosse,
author = {Roger Grosse. (2019)},
title = {Lecture 3: Multilayer Perceptrons},
publisher={[Online.]},
howpublished = {\url{https://www.cs.toronto.edu/~rgrosse/courses/csc421_2019/} (accessed Nov. 13, 2023)}
}
@article{popescu,
author = {Popescu, Marius-Constantin and Balas, Valentina and Perescu-Popescu, Liliana and Mastorakis, Nikos},
year = {2009},
month = {07},
pages = {},
title = {Multilayer perceptron and neural networks},
volume = {8},
journal = {WSEAS Transactions on Circuits and Systems}
}
@misc{grosse2,
author = {Roger Grosse. (2020)},
title = {Lecture 9: Generalization},
publisher={[Online.]},
howpublished = {\url{https://www.cs.toronto.edu/~lczhang/321/notes/notes09.pdf} (accessed Nov. 13, 2023)}
}
@article{reid,
title = {Advanced supervised learning in multi-layer perceptrons — From backpropagation to adaptive learning algorithms},
journal = {Computer Standards & Interfaces},
volume = {16},
number = {3},
pages = {265-278},
year = {1994},
issn = {0920-5489},
doi = {https://doi.org/10.1016/0920-5489(94)90017-5},
url = {https://www.sciencedirect.com/science/article/pii/0920548994900175},
author = {Martin Riedmiller},
keywords = {Supervised learning, Multi-layer perceptrons, Feedforward networks, Adaptive learning algorithms, Benchmark problems, Robustness},
abstract = {Since the presentation of the backpropagation algorithm [1] a vast variety of improvements of the technique for training the weights in a feed-forward neural network have been proposed. The following article introduces the concept of supervised learning in multi-layer perceptrons based on the technique of gradient descent. Some problems and drawbacks of the original backpropagation learning procedure are discussed, eventually leading to the development of more sophisticated techniques This article concentrates on adaptive learning strategies. Some of the most popular learning algorithms are described and discussed according to their classification in terms of global and local adaptation strategies. The behavior of several learning procedures on some popular benchmark problems is reported, thereby illuminating convergence, robustness, and scaling properties of the respective algorithms.}
}
@article{martens,
  author={Martens, J.-P. and Weymaere, N.},
  journal={IEEE Transactions on Neural Networks}, 
  title={An equalized error backpropagation algorithm for the on-line training of multilayer perceptrons}, 
  year={2002},
  volume={13},
  number={3},
  pages={532-541},
  doi={10.1109/TNN.2002.1000122}}
@article{jorge,
author = {Hurtado, Jorge and Alvarez, Diego},
year = {2000},
month = {01},
pages = {},
title = {RELIABILITY ASSESSMENT OF STRUCTURAL SYSTEMS USING NEURAL NETWORKS},
volume = {2000},
journal = {Proc. European Congress on Computational Methods in Applied Sciences and Engineering, ECCOMAS}
}

@misc{lisbon,
author = {Francisco S. Melo},
title = {Neural Networks and the Back-propagation Algorithm},
publisher={Lecture 21},
howpublished = {\url{https://fenix.tecnico.ulisboa.pt/downloadFile/1970943312273599/lec21.notes.pdf} (accessed Nov. 13, 2023)}
}
@article{nielsen1,
author = {Micheal Nielsen},
title = {How the backpropagation algorithm works},
journal = {Neural Networks and Deep Learning},
pages = {39-53},
year = {2015},
publisher = {Determination Press},
URL = { 
        https://www.ise.ncsu.edu/fuzzy-neural/wp-content/uploads/sites/9/2022/08/neuralnetworksanddeeplearning.pdf
},
eprint = { 
        http://neuralnetworksanddeeplearning.com
}
}
@article{nielsen2,
author = {Micheal Nielsen},
title = {Improving the way neural networks learn},
journal = {Neural Networks and Deep Learning},
pages = {59-118},
year = {2015},
publisher = {Determination Press},
URL = { 
        https://www.ise.ncsu.edu/fuzzy-neural/wp-content/uploads/sites/9/2022/08/neuralnetworksanddeeplearning.pdf
},
eprint = { 
        http://neuralnetworksanddeeplearning.com
}
}
@article{zhang,
author = {CHUAN ZHANG TANG and HON KEUNG KWAN},
title = {Parameter effects on convergence speed and generalization capability of backpropagation algorithm},
journal = {International Journal of Electronics},
volume = {74},
number = {1},
pages = {35-46},
year = {1993},
publisher = {Taylor & Francis},
doi = {10.1080/00207219308925810},
URL = { 
        https://doi.org/10.1080/00207219308925810
},
eprint = { 
        https://doi.org/10.1080/00207219308925810
}
}
@article{lecun2010mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume={2},
  year={2010}
}
@article{tom,
author = {Szandała, Tomasz},
year = {2020},
month = {10},
pages = {},
title = {Review and Comparison of Commonly Used Activation Functions for Deep Neural Networks}
}
@book{5python,
  title={Python reference manual},
  author={Van Rossum, Guido and Drake Jr, Fred L},
  year={1995},
  publisher={Centrum voor Wiskunde en Informatica Amsterdam}
}
@Article{         harris2020array,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}
@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}
@Article{Hunter:2007,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}
@misc{openai_gpt3,
  title={Language Models by OpenAI},
  author={OpenAI},
  howpublished={\url{https://www.openai.com/}},
  year={2022},
}
